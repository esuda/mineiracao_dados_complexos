{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho3_DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2mZnz-9JGSA"
      },
      "source": [
        "# Trabalho 3\n",
        "\n",
        "Esse notebook serve como base para o desenvolvimento da Trabalho 3, e deve ser submetido após a conclusão das atividades propostas. \n",
        "\n",
        "Neste trabalho, iremos utilizar uma Rede Generativa Adversarial (GAN) para gerar dígitos de casas do *dataset* SVHN (*Street View House Numbers*). GANs são formadas por duas redes (discriminador e gerador) que são treinadas simultaneamente, sem compartilhamento de pesos. O gerador é responsável por aprender a transformar um ruído aleatório em uma imagem do *dataset* de interesse, enquanto o discriminador é responsável por classificar as imagens em reais e sintéticas (geradas). \n",
        "\n",
        "Abaixo, incluímos alguns imports, e mostramos uma maneira de processar o arquivo `train_32x32.mat` (pode ser baixado [aqui](http://ufldl.stanford.edu/housenumbers/train_32x32.mat)) que contém as imagens do dataset [SVHN](http://ufldl.stanford.edu/housenumbers/).\n",
        "\n",
        "Sugerimos que o código da prática 8 seja estudado, e o mesmo **pode** servir de base para este trabalho, já que o procedimento de treino da GAN não muda.\n",
        "\n",
        "## Depois de cada atividade, inclua uma breve análise do que foi feito e dos resultados!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaBl_YRNGDGi"
      },
      "source": [
        "# Imports\n",
        "Vamos importar as dependências necessárias!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_PJwBq4VZCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9400c76-d8bc-49d7-ac0f-ae6cc7fa6a88"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ZCKgPSnKP7"
      },
      "source": [
        "# Caso queira carregar os dados do drive, descomente as linhas seguintes:\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSxxt7leGlhW"
      },
      "source": [
        "# Carregue o dataset SVHN\n",
        "\n",
        "Os dados são fornecidos em um arquivo .mat, que armazena um dicionário.\n",
        "\n",
        "Para acessar os dados armazenados, utilizamos a função `loadmat` do pacote `scipy`.  Para acessar as imagens, acessamos o campo `['X']` desse dicionário. Um exemplo é mostrado abaixo:\n",
        "\n",
        "Obs.: Lembre-se que para o Keras usando Tensorflow como backend, a dimensão dos canais deve ser a última do seu vetor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ6Nm-Y_ouYI"
      },
      "source": [
        "# Load the dataset\n",
        "X_train = loadmat('gdrive/My Drive/SVHN_Dataset/train_32x32.mat')['X']\n",
        "\n",
        "X_train = np.moveaxis(X_train, -1, 0)\n",
        "print(X_train.shape)\n",
        "\n",
        "plt.imshow(X_train[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nas58_gtK6Sk"
      },
      "source": [
        "# Vanilla GAN com o SVHN\n",
        "A rede mostrada na prática 8 gerava os dígitos do MNIST utilizando camadas densas. Apesar de também conter dígitos, o SVHN possui imagens maiores (32x32), e 3 canais (RGB). Essas diferenças fazem com que a rede precise ser levemente adaptada para poder trabalhar com o novo dataset e gerar novas amostras.\n",
        "\n",
        "Portanto, altere o código da prática 8 para gerar dados do dataset SVHN com as camadas Densas da 'Vanilla' GAN, e mostre os resultados. A 'Vanilla' GAN conseguiu gerar as imagens do (mais complexo) dataset SVHN?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgsb_AQUOkBS"
      },
      "source": [
        "# Adapte o código da prática 8 para gerar dados do SVHN."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWfaJ_O_GN93"
      },
      "source": [
        "# Arquitetura DCGAN\n",
        "\n",
        "Defina aqui a arquitetura do gerador e discriminador da DCGAN seguindo o modelo segundo a imagem abaixo:\n",
        "\n",
        "<img src='https://i.imgur.com/eU2XOxS.png' />\n",
        "\n",
        "Vamos utilizá-la para gerar os dígitos do SVHN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYeC3LpktSdJ"
      },
      "source": [
        "def build_generator(latent_dim):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Adicione as camadas aqui!\n",
        "\n",
        "  #model.summary()\n",
        "  \n",
        "  noise = Input(shape=(latent_dim,))\n",
        "  img = model(noise)\n",
        "\n",
        "  return Model(noise, img)\n",
        "\n",
        "def build_discriminator(img_shape):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Adicione as camadas aqui\n",
        "\n",
        "  #model.summary()\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  validity = model(img)\n",
        "\n",
        "  return Model(img, validity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsDzeXyRKyot"
      },
      "source": [
        "# Treine a DCGAN!\n",
        "\n",
        "Dica: Estude o código mostrado em sala na prática 8, e adapte-o para treinar a DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOicvKh1PW7C"
      },
      "source": [
        "\n",
        "#for iter in range(iterations):\n",
        "\n",
        "  # ---------------------\n",
        "  #  Treino do Discriminador\n",
        "  # ---------------------\n",
        "  \n",
        "  \n",
        "  # ---------------------\n",
        "  #  Treino do Gerador\n",
        "  # ---------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJPXfyhMedok"
      },
      "source": [
        "# Escreva aqui um parágrafo com suas conclusões gerais e análises sobre o experimento proposto.\n",
        "\n",
        "\n"
      ]
    }
  ]
}