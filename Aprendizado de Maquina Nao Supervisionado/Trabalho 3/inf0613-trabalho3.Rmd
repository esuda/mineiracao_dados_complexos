---
title: INF0613 -- Aprendizado de Máquina Não Supervisionado
output: pdf_document
subtitle: Trabalho 3 - Técnicas de Agrupamento
author: 
  - Nome completo Integrante 1
  - Nome completo Integrante 2
  - Nome completo Integrante 3
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE, message = FALSE, warning = FALSE, tidy = FALSE)
options(digits = 3)
```


O objetivo deste trabalho é exercitar o uso de algoritmos de agrupamento. Neste trabalho, vamos analisar diferentes atributos de carros com o objetivo de verificar se seus atributos são suficientes para indicar um valor de risco de seguro. O conjunto de dados já apresenta o risco calculado no campo `symboling` indicado na Tabela 1. Quanto mais próximo de 3, maior o risco. O conjunto de dados que deve ser usado está disponível na página do Moodle com o nome `imports-85.data`.

# Atividade 0 -- Configurando o ambiente
Antes de começar a implementação do seu trabalho configure o _workspace_ e importe todos os pacotes e execute o preprocessamento da base:

```{r atv0-code}
# Adicione os pacotes usados neste trabalho:
#install packages
#install.packages("apcluster")
#install.packages("fclust")
#install.packages("ppclust")
#install.packages("dbscan")
#install.packages("gridExtra")
#install.packages("fpc")
#install.packages("NbClust")
#install.packages("factoextra")
#install.packages("NbClust")

library(dplyr)
library(ggplot2)
library(factoextra)
library(NbClust)
library(fpc)
library(gridExtra)
library(dbscan)
library(ppclust)
library(fclust)
library(apcluster)
library ( NbClust )


#Funções extras 
onehot_features <- function(dataset, feature){
    cats <- unique(dataset[, feature])
    for (cat in cats){
        dataset[cat] <- as.numeric(dataset[,feature]==cat)
    }
    return(dataset)
}

min_max <- function(df, columns){
  min_features <- apply(df[,colnames(df) %in% columns], 2, min); min_features
  max_features <- apply(df[,colnames(df) %in% columns], 2, max); max_features
  diff <- max_features - min_features; diff
  df[,colnames(df) %in% columns] <- sweep(df[,colnames(df) %in% columns], 2, min_features, "-")
  df[,colnames(df) %in% columns] <- sweep(df[,colnames(df) %in% columns], 2, diff, "/")
  return(df)

}


# Configure ambiente de trabalho na mesma pasta 
# onde colocou a base de dados:
# setwd("")
# setwd("C:\\Users\\Eric\\Documents\\GitHub\\mineiracao_dados_complexos\\Aprendizado de Maquina Nao Supervisionado\\Trabalho 3")
setwd("/Users/nkuros/Documents/mineiracao_dados_complexos/Aprendizado de Maquina Nao Supervisionado/Trabalho 3/")

```



# Atividade 1 -- Análise e Preparação dos Dados

O conjunto de dados é composto por 205 amostras com 26 atributos cada descritos na Tabela 1. Os atributos são dos tipos `factor`, `integer` ou  `numeric`. O objetivo desta etapa é a análise e preparação desses dados de forma a ser possível agrupá-los nas próximas atividades. 

**Implementações:** Nos itens a seguir você implementará a leitura da base e aplicará tratamentos básicos.

a) *Tratamento de dados Incompletos:* Amostras incompletas deverão ser tratadas, e você deve escolher a forma que achar mais adequada. Considere como uma amostra incompleta uma linha na qual faltam dados em alguma das colunas selecionadas anteriormente. Note que, dados faltantes nas amostras podem causar uma conversão do tipo do atributo de todas as amostras e isso pode impactar no item b). 

```{r atv1a-code}
# Leitura da base
df <- read.table('imports-85.data',sep=',')
set.seed (12345)
# Tratamento de dados faltantes

# Avaliacao do dataset
summary(df)
head(df)

# Avalaiacao dos valores unicos de cada coluna
for(col in colnames(df)){
  print(col)
  print(unique(df[,col]))
  print('\n')
}

#------------------------------------------------------------------------
# Tratando "?" que apresenta nas bases para poder transformar em numerico
df$V2 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V2))
df$V6 <- gsub(pattern='[?]', replacement=NA, df$V6)
df$V19 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V19))
df$V20 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V20))
df$V22 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V22))
df$V23 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V23))
df$V26 <- as.numeric(gsub(pattern='[?]', replacement=NA, df$V26))

unique(df$V6)
unique(df$V18)

#----------------------------------------
# Data set de teste retirando todos os NA
df2 <- na.omit(df)
summary(df2)
#----------------------------------------

# NA de V19 e V20 sao para a mesma marca mazda
df[is.na(df$V19),]
df[df$V3=='mazda',]
# Agrupando os valores para obter a m[edia de V19 e V20]
linhas = df$V3=='mazda' & !is.na(df$V19)
colunas = c('V3', 'V19', 'V20')
media_mazda = df[linhas,colunas] %>% group_by(V3) %>% summarise(media_v19=median(V19), media_V20=median(V20))
# Substituindo V19 e V20 que estao NA pela media
df[df$V3=='mazda' & is.na(df$V19),'V19'] = media_mazda$media_v19
df[df$V3=='mazda' & is.na(df$V20),'V20'] = media_mazda$media_V20

#----------------------------------------------------------------------------------------
# Como temos apenas 2 carros da marca renault, vamos observar a distribuicao de V22 e V23
df[is.na(df$V22),]
df[df$V3=='renault',]

# Distribuicoes nao normais e outliers, vamos pela mediana
ggplot(df, aes(x=V22, y= ..density..)) +
  geom_histogram(color='White', bins=10) +
  geom_density()
ggplot(df, aes(x=V23, y= ..density..)) +
  geom_histogram(color='White', bins=10) +
  geom_density()

linhas <- !is.na(df$V22)
colunas <- c('V22', 'V23')
media_renault <- df[linhas,colunas] %>% summarise(mediana_v22=median(V22), mediana_V23=median(V23))

df[df$V3=='renault' & is.na(df$V22),'V22'] = media_renault$mediana_v22
df[df$V3=='renault' & is.na(df$V23),'V23'] = media_renault$mediana_V23

#----------------------------------------
# Verificacao dos veiculos com preco NA
df[is.na(df$V26),]
# Marcas para verificar 'audi', 'isuzu', 'porsche'
df[df$V3 %in% c('audi', 'isuzu', 'porsche'),]

#df[df$V3 %in% c('audi', 'isuzu', 'porsche') & !is.na(df$V26), c('V3', 'V26')] 
#    %>% group_by(V3) 
#    %>% summarise(max=max(V26), min=min(V26), mean=mean(V26), median=median(V26))

linhas <- df$V3 %in% c('audi', 'isuzu', 'porsche') & !is.na(df$V26)
colunas <- c('V3', 'V26')
median_marcas <- df[linhas, colunas] %>% group_by(V3) %>% summarise(median_26=median(V26))

for (marca in unique(median_marcas$V3)){
  df[df$V3==marca & is.na(df$V26),'V26'] <- median_marcas[median_marcas$V3==marca,'median_26']
}

#----------------------
# Verificando coluna V2
teste <- df[df$V3 %in% unique(df[is.na(df$V2),'V3']),]
teste

# Para as marcas que possuem mais carros com V2 nao nulo, tiramos a media
linhas <- df$V3 %in% unique(df[is.na(df$V2),'V3']) & !is.na(df$V2)
colunas <- c('V3', 'V2')
media_marcas <- df[linhas, colunas] %>% group_by(V3) %>% summarise(median_2=median(V2))
media_marcas

for (marca in unique(media_marcas$V3) ){
  df[df$V3==marca & is.na(df$V2),'V2'] <- media_marcas[media_marcas$V3==marca,'median_2']
}

# Para as marcas em que todos os carros apresentam V2 nulo, tiramos a mediana da base
ggplot(df, aes(x=V2, y= ..density..)) +
  geom_histogram(color='White', bins=10) +
  geom_density()

linhas <- !is.na(df$V2)
colunas <- 'V2'
mediana_marcas <- median(df[linhas, colunas])
mediana_marcas

for (marca in unique(df[is.na(df$V2), 'V3'])) {
  df[df$V3==marca & is.na(df$V2),'V2'] <- mediana_marcas
}
# retirando duas linhas
# df <- na.omit(df, cols='V6')

# Criando features Categoricas via One Hot Encoding
df = onehot_features(df, 'V3')
df = onehot_features(df, 'V4')
df = onehot_features(df, 'V5')
#df = onehot_features(df, 'V6')
df = onehot_features(df, 'V7')
df = onehot_features(df, 'V8')
df = onehot_features(df, 'V9')
df = onehot_features(df, 'V15')
df = onehot_features(df, 'V16')
df = onehot_features(df, 'V18')

# NORMALIZAR AS VARIAVEIS
summary(df)

```

b) *Seleção de Atributos:* Atributos não-numéricos não podem ser usados com as técnicas  agrupamento vistas em aula. Portanto, você deve selecionar um conjunto de atributos numéricos que serão usados para o agrupamento. Além disso você deve analisar se os atributos não-numéricos são descritivos para a realização dos agrupamentos. Caso um dos atributos não numéricos seja necessário, use a técnica do  *one hot encoding* para transformá-lo em numérico. **Não** aplique essa técnica nos atributos `symboling` e `make` para os agrupamentos subsequentes, eles não devem fazer parte do agrupamento. 

```{r atv1b-code}
# Seleção de atributos

# Iremos descartar todas as variaveis categoricas que possuem apenas duas categorias, pois nao faz sentido na hora de realizar os algoritmos de clusterizacao por distancia.
# Alem de descartar as variaveis categoricas body-style, drive-wheels, engine-type, fuel-system


```

## Análises

Após as implementações escreva uma análise da base de dados. Em especial, descreva o conjunto de dados inicial, relate como foi realizado o tratamento, liste quais os atributos escolhidos para manter na base e descreva a base de dados após os tratamentos listados. Explique todos os passos executados, mas sem copiar códigos na análise. Além disso justifique suas escolhas de tratamento nos dados faltantes e seleção de atributos.


**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->


# Atividade 2 -- Agrupamento com o $K$*-means*

Nesta atividade, você deverá agrupar os dados com o algoritmo $K$*-means* e utilizará duas métricas básicas para a escolha do melhor $K$: a soma de distâncias intra-cluster e o coeficiente de silhueta. 

**Implementações:** Nos itens a seguir você implementará a geração de gráficos para a análise das distâncias intra-cluster e do coeficiente de silhueta. Em seguida, você implementará o agrupamento dos dados processados na atividade anterior com o algoritmo $K$*-means* utilizando o valor de $K$ escolhido.  

a) *Gráfico \textsl{Elbow Curve}:* Construa um gráfico com a soma das distâncias intra-cluster para $K$ variando de $2$ a $30$.

```{r atv2a-code}
# Construindo um gráfico com as distâncias intra-cluster
#colunas_porta = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "four")
#colunas_tracao = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "rwd", "fwd")
#colunas_cilindro = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "four", "six", "five", "three", "twelve", "two")
colunas_full = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "convertible", "hatchback", "sedan", "wagon", "four", "six", "five", "three", "twelve", "two")

#colunas = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "convertible", "hatchback", "sedan", "wagon")
colunas = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26")
numericas = c("V2", "V10", "V11", "V12", "V13", "V14", "V17", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26")

df_normalized <- min_max(df,numericas)
summary(df_normalized)
colnames(df_normalized)
##### ALGORITIMO PARA TAMANHO DE CLUSTERS ####
base_1 = df_normalized[, colunas_full]


nb <- NbClust ( base_1 , distance ="euclidean",min.nc =2 , max.nc =30 , method ="complete",index ="all")

for(col in colnames(base_1)){
  print(col)
  print(unique(df[,col]))
  print('----------------------------')
}

fviz_nbclust(base_1, kmeans, method="wss",k.max=3)
#--------------------------

# Aplica a tecnica K-Means
base_kmeans <- eclust(base_1, "kmeans", k=30,nstart=25, graph=TRUE)

#TESTE KMEANS COM 3 para análise de grupos
base_kmeans_test <- kmeans(base_1 , 3, nstart = 20)
test_df <- as.data.frame.matrix(table(base_kmeans_test$cluster, df_normalized$V1));test_df

### <<<<<<<<----- TESTE DE CORRELAÇÃO * APLICAR FX , tirar/ colocar  vars *

# Mostra o numero do grupo de cada amostra
base_kmeans$cluster


# Visualiza os grupos




```

b) *Gráfico da Silhueta:* Construa um gráfico com o valor da silhueta para $K$ variando de $2$ a $30$.

```{r atv2b-code}
# Construindo um gráfico com os valores da silhueta
fviz_nbclust(base_1, kmeans, method="silhouette", k.max=30)

```

c) *Escolha do $K$:* Avalie os gráficos gerados nos itens anteriores e escolha o melhor valor  de $K$ com base nas informações desses gráficos e na sua análise. Se desejar, use também a função `NbClust` para ajudar nas análises. Com o valor de $K$ definido, utilize o rótulo obtido para cada amostra, indicando o grupo ao qual ela pertence, para gerar um gráfico de dispersão (atribuindo cores diferentes para cada grupo).

```{r atv2c-code}
# Aplicando o k-means com o k escolhido 
base_kmeans <- eclust(base_1, "kmeans", k=7,nstart=25, graph=FALSE)

# Construindo um gráfico de dispersão
fviz_cluster(base_kmeans, geom="point", ellipse.type="norm")
base_kmeans$cluster
```

## Análises

Descreva cada um dos gráficos gerados nos itens acima e analise-os. Inclua na sua análise as informações mais importantes que podemos retirar desses gráficos. Discuta sobre a escolha do valor $K$ e sobre a apresentação dos dados no gráfico de dispersão. 


**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

# Atividade 3 -- Agrupamento com o *DBscan*

Nesta atividade, você deverá agrupar os dados com o algoritmo *DBscan*. Para isso será necessário experimentar com diferentes valores de *eps* e *minPts*. 

a) *Ajuste de Parâmetros:* Experimente com valores diferentes para os parâmetros *eps* e *minPts*. Verifique o impacto dos diferentes valores nos agrupamentos.

```{r atv3a-code}
# Experimento com valores de eps e minPts
 db <- dbscan :: dbscan ( base_1 , eps=1 , minPts=5)
 print(db)
# Experimento com valores de eps e minPts
 db <- dbscan :: dbscan ( base_1 , eps =0.25, minPts =5)
 print(db)
# Experimento com valores de eps e minPts
 db <- dbscan :: dbscan ( base_1 , eps =0.10 , minPts =5)
 print(db)

```

b) *Determinando Ruídos:* Escolha o valor de *minPts* que obteve o melhor resultado no item anterior e use a função `kNNdistplot` do pacote `dbscan` para determinar o melhor valor de *eps* para esse valor de *minPts*. Lembre-se que o objetivo não é remover todos os ruídos. 

```{r atv3b-code}
# Encontrando o melhor eps com o kNNdistplot
dbscan :: kNNdistplot (base_1 , k =5)
```

c) *Visualizando os Grupos:* Após a escolha dos parâmetros *eps* e *minPts*, utilize o rótulo obtido para cada amostra, indicando o grupo ao qual ela pertence, para gerar um gráfico de dispersão (atribuindo cores diferentes para cada grupo).

```{r atv3c-code}
# Aplicando o DBscan com os parâmetros escolhidos
 db <- dbscan :: dbscan ( base_1 , eps =0.60 , minPts =5)
 print(db)

# Construindo um gráfico de dispersão
fviz_cluster(db, data=base_1, stand=FALSE, 
             ellipse=FALSE, show.clust.cent=FALSE, 
             geom="point", palette="jco",
             ggtheme=theme_classic())

#analise matriz cruzada

#base_kmeans_test <- kmeans(base_1 , 3, nstart = 20)
analise <- as.data.frame.matrix(table(db$cluster, df_normalized$V1));analise

```

## Análises

Descreva os experimentos feitos para a escolha dos parâmetros *eps* e *minPts*. Inclua na sua análise as informações mais importantes que podemos retirar dos gráficos gerados. Justifique a escolha dos valores dos parâmetros e analise a apresentação dos dados no gráfico de dispersão. 


**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

# Atividade 4 -- Comparando os Algoritmos

<!-- Use o espaço abaixo para escrever os códigos necessários 
	para responder as perguntas a seguir  -->

```{r atv4-code}

```

Com base nas atividades anteriores, faça uma conclusão dos seus experimentos respondendo às seguintes perguntas: 

a) Qual dos métodos apresentou melhores resultados? Justifique.

b) Quantos agrupamentos foram obtidos?

c) Analisando o campo `symboling` e o grupo designado para cada amostra, os agrupamentos conseguiram separar os níveis de risco?

d) Analisando o campo `make` que contém as marcas dos carros, os agrupamentos conseguiram separar as marcas?


**Respostas:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->




