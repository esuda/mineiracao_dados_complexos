#### Aprendizado de Maquina Não Supervisionado
#### Prof. Helio Pedrini
####
#### Codigos dos slides da Aula 4 - Técnicas de Agrupamento
# Carrega o conjunto de dados
library(datasets)
data(iris)
# Apresenta um resumo da base:
summary(iris)
# Calcula a matriz de distancias:
d <- dist(iris[, 3:4], method="euclidean")
# Visualiza a matriz de distancias com a funcao heatmap
heatmap(as.matrix(d), symm=TRUE)
# Aplica o algoritmo de agrupamento hierarquico
clusters <- hclust(d, method="complete")
# Apresenta o dendrograma resultante:
plot(clusters)
# Corta o dendrograma no numero k de grupos e retorna o
# agrupamento dos dados
clusters_cut <- cutree(clusters, k=3)
# Mostra os resultados
table(clusters_cut, iris$Species)
# Visualiza os agrupamentos
library(ggplot2)
ggplot(iris, aes(Petal.Length, Petal.Width,
color=Species)) +
geom_point(alpha=0.4, size=3.5) +
geom_point(col=clusters_cut) +
scale_color_manual(values=c('black', 'red', 'green'))
# Outra estrategia de proximidade pode ser avaliada:
clusters <- hclust(d, method='average')
# Apresenta o dendrograma resultante
plot(clusters)
# Atribuindo-se o numero de grupos igual a 3
clusters_cut <- cutree(clusters, k=3)
# Mostra os resultados
table(clusters_cut, iris$Species)
# Visualiza os agrupamentos
ggplot(iris, aes(Petal.Length, Petal.Width,
color=Species)) +
geom_point(alpha=0.4, size=3.5) +
geom_point(col=clusters_cut) +
scale_color_manual(values=c('black', 'red', 'green'))
# Aplica o algoritmo K-Means com k=3
# Resultados podem variar devida a aleatoriedade
cl1 <- kmeans(iris[,1:4], 3)
cl1
# Retorna o numero de pontos em cada grupo
cl1$size
# Retorna o numero de centroides
cl1$centers
# Retorna a indicacao do grupo de cada dado
cl1$cluster
# Retorna a matriz de resultados
table(cl1$cluster, iris$Species)
# Diferente inicializacao
cl2 <- kmeans(iris[,1:4], 3, nstart=20)
cl2
# Calcula a matriz de dissimilaridades
library(cluster)
dissE <- daisy(iris[,1:4])
# Calcula as silhuetas
sk <- silhouette(cl1$cl, dissE)
# Apresenta as silhuetas
plot(sk)
# Outra forma de calcular e visualizar as silhuetas
library(factoextra)
fviz_silhouette(sk)
# Determina o numero otimo de grupos
library(NbClust)
# remove coluna com rótulos das classes e escala os dados
iris.scaled <- scale(iris[, -5])
# Gera os graficos referentes as medidas Hubert index e D index
# São gerados 4 gráficos
nb <- NbClust(iris.scaled, distance="euclidean",
min.nc=2, max.nc=10, method="complete",
index="all")
# Outra forma de determinar o numero otimo de grupos.
library(factoextra)
fviz_nbclust(nb) + theme_minimal()
# Valor de cl$totss
cl1$totss
# Valor de cl1$withinss
cl1$withinss
# Valor de cl1$tot.withinss
cl1$tot.withinss
# Valor de cl1$betweenss
cl1$betweenss
# Pode-se ainda calcular um conjunto variado de medidas
# estatísticas para o algoritmo K-Means
library(fpc)
# Compute pairwise-distance matrices
dd <- dist(iris.scaled, method="euclidean")
# Statistics for k-means clustering
km_stats <- cluster.stats(dd, cl1$cluster)
km_stats
# Aplica a tecnica K-Means
km.res <- eclust(iris.scaled, "kmeans", k=3,
nstart=25, graph=FALSE)
# Mostra o numero do grupo de cada amostra
km.res$cluster
# Visualiza os grupos (versão depreciada)
# fviz_cluster(km.res, geom="point", ellipse.type="norm")
# Visualiza os grupos
fviz_cluster(km.res, geom="point", ellipse.type="norm")
# Aplica a tecnica PAM
pam.res <- eclust(iris.scaled, "pam", k=3, graph=FALSE)
# Mostra o numero do grupo de cada amostra
pam.res$cluster
# Visualiza os grupos
fviz_cluster(pam.res, geom ="point", ellipse.type ="norm")
# Carrega pacotes e base
library(cluster)
library(factoextra)
library(NbClust)
data(USArrests)
# Remove dados faltantes e normaliza dados
df <- USArrests
df <- na.omit(df)
df <- scale(df)
# Apresenta os resultados
head(df, n=3)
# Aplica a tecnica K-Means com dois grupos
set.seed(123)
k2 <- kmeans(df, centers=2, nstart=25)
k2
# Adiciona classificacao aos dados originais
dd <- cbind(USArrests, cluster=k2$cluster)
head(dd)
# Mostra o tamanho dos grupos
k2$size
# Mostra o numero dos grupos para cada amostra
k2$cluster
head(k2$cluster, 4)
# Mostra os centroides dos grupos
k2$centers
# Visualiza os resultados
fviz_cluster(k2, data=df)
# Testa diferentes numeros de grupos
k3 <- kmeans(df, centers=3, nstart=25)
k4 <- kmeans(df, centers=4, nstart=25)
k5 <- kmeans(df, centers=5, nstart=25)
# Mostra os agrupamentos
p1 <- fviz_cluster(k2, geom="point", data=df) + ggtitle("k=2")
p2 <- fviz_cluster(k3, geom="point", data=df) + ggtitle("k=3")
p3 <- fviz_cluster(k4, geom="point", data=df) + ggtitle("k=4")
p4 <- fviz_cluster(k5, geom="point", data=df) + ggtitle("k=5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow=2)
# Determina o numero de grupos
set.seed(123)
fviz_nbclust(df, kmeans, method="wss")
# Determina o numero de grupos (medida de silhueta)
fviz_nbclust(df, kmeans, method="silhouette")
# Extrai resultados, assumindo um numero de grupos igual a 4
set.seed(123)
final <- kmeans(df, centers=4, nstart=25)
print(final)
# Visualiza os resultados
fviz_cluster(final, data = df)
# # Carregando base wine com arquivo offline
# # baixado do Moodle:
# wine <- read.table(file.choose(), sep=",")
# Carrega base de dados com arquivo online
wine <-
read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data",
sep=",")
# Normaliza os dados
wine.stand <- scale(wine[-1])
# Aplica a tecnica de agrupamentos K-Means
km <- kmeans(wine.stand, 3)
# Apresenta os centroides do grupos
km$centers
# Apresenta os grupos
km$cluster
# Apresenta os tamanhos dos grupos
km$size
# Visualiza os grupos
library(cluster)
clusplot(wine.stand, km$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
# Mostra o desempenho dos agrupamentos
table(wine[,1], km$cluster)
# Aplica a tecnica de agrupamento hierarquico, tendo como entrada uma matriz de distancias
d <- dist(wine.stand, method="euclidean")
h <- hclust(d, method="ward.D")
# Visualiza dendrograma
plot(h)
# Corta o dendrograma em 5 grupos e mostra o desempenho dos agrupamentos
groups <- cutree(h, k=3)
table(wine[,1], groups)
# Apresenta medidas de desempenho
km$betweenss
km$withinss
km$tot.withinss
km$totss
# Instala pacotes e carrega base
# install.packages("dbscan")
library(dbscan)
data(multishapes, package="factoextra")
dados <- multishapes[, 1:2]
# Executa algoritmo de agrupamentos DBSCAN
set.seed(123)
db <- dbscan::dbscan(dados, eps=0.15, minPts=5)
# Apresenta os resultados
print(db)
# Visualiza os grupos
# # Note que aqui usamos apenas a função plot pois os dados
# # possuem apenas duas dimensões, para criar gráficos de
# # dispersão para bases com mais dimensões use as funções
# # do pacote fviz.
plot(dados, col=db$cluster)
points(dados[db$cluster==0,], pch=3, col="grey")
# Outra forma de visualizar os agrupamentos
library("factoextra")
fviz_cluster(db, data=dados, stand=FALSE,
ellipse=FALSE, show.clust.cent=FALSE,
geom="point", palette="jco",
ggtheme=theme_classic())
plot(dados, col=db$cluster)
points(dados[db$cluster==0,], pch=3, col="grey")
graphics.off()
fviz_cluster(db, data=dados, stand=FALSE,
ellipse=FALSE, show.clust.cent=FALSE,
geom="point", palette="jco",
ggtheme=theme_classic())
